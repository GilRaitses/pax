Great! Task 1.1 (YOLOv8n) is complete. Let's continue with the remaining BRANCH 1 tasks.

Task 1.2: Set up Detectron2 for instance segmentation.
- Install detectron2 (check compatibility with Python version)
- Create wrapper: src/pax/vision/detectron2.py
- Configure for instance segmentation
- Test on sample images
- Output: Detailed object boundaries, crowd density metrics

Task 1.3: Set up CLIP for scene understanding.
- Install transformers or clip package
- Create wrapper: src/pax/vision/clip.py
- Create scene understanding wrapper
- Test on sample images
- Output: Scene labels, semantic features

Task 1.4: Create Feature Extraction Pipeline.
- Create unified feature extraction function: src/pax/vision/extractor.py
- Combine all three models (YOLOv8n, Detectron2, CLIP)
- Handle errors gracefully
- Create single script that extracts all features from an image
- Output: Single script that extracts all features

Task 1.5: Extract Features from Current Images.
- Process all ~495 images currently collected
- Store features in structured format (JSON or Parquet)
- Generate extraction report
- Output: Feature dataset for all images

Once Task 1.5 is complete, BRANCH 3 can start!
