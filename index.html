<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Pax NYC - Traffic Camera Collection Dashboard</title>
    <link rel="stylesheet" href="https://unpkg.com/leaflet@1.9.4/dist/leaflet.css" />
    <script src="https://unpkg.com/leaflet@1.9.4/dist/leaflet.js"></script>
    <script src="https://unpkg.com/d3-delaunay@6.0.2/dist/d3-delaunay.umd.js"></script>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: #333;
            padding: 20px;
            min-height: 100vh;
        }
        
        .container {
            max-width: 1400px;
            margin: 0 auto;
        }
        
        header {
            text-align: center;
            color: white;
            margin-bottom: 30px;
        }
        
        h1 {
            font-size: 2.5em;
            font-weight: 700;
            margin-bottom: 10px;
        }
        
        .subtitle {
            font-size: 1.1em;
            opacity: 0.9;
        }
        
        .stats-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
            gap: 20px;
            margin-bottom: 30px;
        }
        
        .stat-card {
            background: white;
            border-radius: 12px;
            padding: 25px;
            box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
            transition: transform 0.2s;
        }
        
        .stat-card:hover {
            transform: translateY(-5px);
            box-shadow: 0 8px 12px rgba(0, 0, 0, 0.15);
        }
        
        .stat-label {
            font-size: 0.9em;
            color: #666;
            text-transform: uppercase;
            letter-spacing: 1px;
            margin-bottom: 8px;
        }
        
        .stat-value {
            font-size: 2.5em;
            font-weight: 700;
            color: #667eea;
        }
        
        .stat-subtext {
            font-size: 0.85em;
            color: #999;
            margin-top: 5px;
        }
        
        .live-preview-section {
            background: white;
            border-radius: 12px;
            padding: 25px;
            margin-bottom: 30px;
            box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
        }

        .live-preview-title {
            font-size: 1.3em;
            font-weight: 700;
            color: #667eea;
            margin-bottom: 15px;
            display: flex;
            align-items: center;
            gap: 10px;
        }

        .live-indicator {
            width: 12px;
            height: 12px;
            background: #48bb78;
            border-radius: 50%;
            animation: pulse 2s infinite;
        }

        @keyframes pulse {
            0%, 100% { opacity: 1; }
            50% { opacity: 0.5; }
        }

        .image-preview-container {
            display: grid;
            grid-template-columns: 1fr 300px;
            gap: 20px;
            margin-top: 15px;
        }

        .preview-image-wrapper {
            position: relative;
            background: #f8f9fa;
            border-radius: 8px;
            overflow: hidden;
            aspect-ratio: 16/9;
            display: flex;
            align-items: center;
            justify-content: center;
        }

        .preview-image {
            max-width: 100%;
            max-height: 100%;
            object-fit: contain;
        }

        .preview-placeholder {
            color: #999;
            font-size: 0.9em;
            text-align: center;
        }

        .preview-info {
            display: flex;
            flex-direction: column;
            gap: 10px;
        }

        .preview-info-item {
            background: #f8f9fa;
            padding: 12px;
            border-radius: 6px;
        }

        .preview-info-label {
            font-size: 0.75em;
            color: #666;
            text-transform: uppercase;
            letter-spacing: 0.5px;
            margin-bottom: 4px;
        }

        .preview-info-value {
            font-size: 1em;
            font-weight: 600;
            color: #333;
        }

        .map-section {
            background: white;
            border-radius: 12px;
            padding: 25px;
            margin-bottom: 30px;
            box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
        }

        .map-title {
            font-size: 1.5em;
            font-weight: 700;
            color: #667eea;
            margin-bottom: 15px;
        }

        #cameraMap {
            width: 100%;
            height: 600px;
            border-radius: 8px;
            overflow: hidden;
            border: 2px solid #e0e0e0;
        }

        .camera-marker {
            cursor: pointer;
            transition: transform 0.2s;
        }

        .camera-marker:hover {
            transform: scale(1.2);
        }

        .voronoi-cell {
            fill: rgba(102, 126, 234, 0.1);
            stroke: rgba(102, 126, 234, 0.3);
            stroke-width: 1;
            pointer-events: none;
        }

        .camera-popup {
            min-width: 250px;
        }

        .camera-popup-header {
            display: flex;
            justify-content: space-between;
            align-items: start;
            margin-bottom: 8px;
        }

        .camera-popup-name {
            font-weight: 600;
            font-size: 1.05em;
            color: #333;
            flex: 1;
        }

        .camera-popup-badge {
            background: #667eea;
            color: white;
            padding: 4px 10px;
            border-radius: 12px;
            font-size: 0.75em;
            font-weight: 600;
            text-transform: uppercase;
        }

        .camera-popup-badge.high { background: #f56565; }
        .camera-popup-badge.medium { background: #ed8936; }
        .camera-popup-badge.low { background: #48bb78; }

        .camera-popup-meta {
            font-size: 0.85em;
            color: #666;
            margin-bottom: 8px;
        }

        .camera-popup-count {
            font-size: 1.8em;
            font-weight: 700;
            color: #667eea;
            margin: 10px 0;
        }

        .camera-popup-last {
            font-size: 0.8em;
            color: #999;
        }

        .storage-info {
            background: rgba(255, 255, 255, 0.1);
            color: white;
            padding: 15px;
            border-radius: 8px;
            margin-top: 20px;
            margin-bottom: 30px;
            font-size: 0.9em;
        }
        
        .section-title {
            color: white;
            font-size: 1.5em;
            font-weight: 600;
            margin-bottom: 20px;
            margin-top: 30px;
        }
        
        .error-message {
            background: #fed7d7;
            color: #c53030;
            padding: 15px;
            border-radius: 8px;
            margin-bottom: 20px;
            display: none;
        }
        
        .proposal-section {
            background: white;
            border-radius: 12px;
            padding: 40px;
            margin-bottom: 30px;
            box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
        }
        
        .proposal-section h2 {
            color: #667eea;
            font-size: 1.8em;
            margin-bottom: 20px;
            border-bottom: 2px solid #667eea;
            padding-bottom: 10px;
        }
        
        .proposal-section h3 {
            color: #764ba2;
            font-size: 1.3em;
            margin-bottom: 12px;
            margin-top: 0;
        }
        
        .proposal-card {
            background: #f8f9fa;
            padding: 20px;
            border-radius: 8px;
            border-left: 4px solid #667eea;
        }
        
        .proposal-card p {
            margin: 0;
            line-height: 1.6;
        }
        
        code {
            background: #e9ecef;
            padding: 2px 6px;
            border-radius: 3px;
            font-family: 'Courier New', monospace;
            font-size: 0.9em;
            color: #d63384;
        }

        .refresh-indicator {
            position: fixed;
            bottom: 20px;
            right: 20px;
            background: white;
            padding: 12px 20px;
            border-radius: 25px;
            box-shadow: 0 4px 12px rgba(0, 0, 0, 0.15);
            font-size: 0.9em;
            display: flex;
            align-items: center;
            gap: 10px;
        }
        
        .spinner {
            width: 16px;
            height: 16px;
            border: 2px solid #f3f3f3;
            border-top: 2px solid #667eea;
            border-radius: 50%;
            animation: spin 1s linear infinite;
        }
        
        @keyframes spin {
            0% { transform: rotate(0deg); }
            100% { transform: rotate(360deg); }
        }

        @media (max-width: 768px) {
            .image-preview-container {
                grid-template-columns: 1fr;
            }
            #cameraMap {
                height: 400px;
            }
        }
    </style>
</head>
<body>
    <div class="container">
        <header>
            <h1 style="font-size: 2.8em; margin-bottom: 15px;">Energetic Pathfinding and Perceptual Heuristics</h1>
            <div class="subtitle" style="font-size: 1.3em; margin-bottom: 10px;">Manhattan Navigation via Learned A* Search</div>
            <div style="margin-top: 15px; font-size: 0.95em; opacity: 0.9;">
                <div>CIS 667: Introduction to Artificial Intelligence – Term Project</div>
                <div style="margin-top: 8px;">Gil Raitses | Syracuse University | Data Science / HCAI Program</div>
            </div>
        </header>

        <div class="error-message" id="errorMessage"></div>
        
        <div class="stats-grid">
            <div class="stat-card">
                <div class="stat-label">Total Images</div>
                <div class="stat-value" id="totalImages">0</div>
                <div class="stat-subtext">Captured frames</div>
            </div>
            
            <div class="stat-card">
                <div class="stat-label">Active Cameras</div>
                <div class="stat-value" id="activeCameras">0</div>
                <div class="stat-subtext">Monitored locations</div>
            </div>
            
            <div class="stat-card">
                <div class="stat-label">Latest Capture</div>
                <div class="stat-value" id="latestCapture" style="font-size: 1.2em;">--</div>
                <div class="stat-subtext">Last collection time</div>
            </div>
            
            <div class="stat-card">
                <div class="stat-label">Collection Rate</div>
                <div class="stat-value" id="collectionRate">30</div>
                <div class="stat-subtext">Minutes per cycle</div>
            </div>
        </div>

        <div class="live-preview-section">
            <div class="live-preview-title">
                <span class="live-indicator"></span>
                Current Image Being Saved
            </div>
            <div class="image-preview-container">
                <div class="preview-image-wrapper">
                    <img id="previewImage" class="preview-image" src="" alt="Latest captured image" style="display: none;">
                    <div id="previewPlaceholder" class="preview-placeholder">No image available yet</div>
                </div>
                <div class="preview-info">
                    <div class="preview-info-item">
                        <div class="preview-info-label">Camera</div>
                        <div class="preview-info-value" id="previewCameraName">--</div>
                    </div>
                    <div class="preview-info-item">
                        <div class="preview-info-label">Timestamp</div>
                        <div class="preview-info-value" id="previewTimestamp">--</div>
                    </div>
                    <div class="preview-info-item">
                        <div class="preview-info-label">Captured</div>
                        <div class="preview-info-value" id="previewCapturedAt">--</div>
                    </div>
                </div>
            </div>
        </div>

        <div class="storage-info">
            <strong>Storage:</strong> <span id="storageInfo">Loading...</span>
        </div>

        <div class="map-section">
            <div class="map-title">Camera Coverage Map - Voronoi Cells & State Space</div>
            <div id="cameraMap"></div>
        </div>

        <div class="proposal-section">
            <h2>Introduction</h2>
            <p style="font-size: 1.05em; line-height: 1.7; color: #333; margin-bottom: 25px;">
                Traditional pathfinding algorithms optimize for geometric distance or travel time but fail to capture the 
                <strong>energetic and perceptual dynamics</strong> of movement in dense urban environments. In Manhattan, 
                the cost of traversing a route is not defined by distance alone but by <strong>sensory and behavioral complexity</strong>: 
                crowding, visual noise, infrastructure gaps and movement unpredictability.
            </p>

            <p style="font-size: 1.1em; line-height: 1.7; color: #333; font-weight: 600; margin: 25px 0;">
                <strong>Key Research Question:</strong> Can learned heuristics from vision-based environmental features outperform 
                standard Manhattan-distance baselines in predicting route stress and improving path interpretability?
            </p>

            <p style="font-size: 1.05em; line-height: 1.7; color: #333;">
                This work develops a <strong>perceptually informed heuristic</strong> for A* search using NYC traffic camera data. 
                The heuristic models environmental resistance by extracting features from visual data. Human pedestrians naturally 
                avoid stressful routes based on crowded intersections, poor lighting and aggressive traffic patterns; this approach 
                encodes similar avoidance behavior.
            </p>

            <div style="background: #f8f9fa; padding: 25px; border-radius: 12px; margin: 30px 0; border-left: 4px solid #667eea;">
                <h3 style="color: #667eea; margin-top: 0;">Aim</h3>
                <p style="margin: 0; font-size: 1.05em; line-height: 1.6;">
                    Implement and evaluate a heuristic search system that learns energetic pathfinding behavior by integrating 
                    sensory data into classical A* reasoning. Test whether perception-driven cost modeling improves interpretability 
                    and environmental realism in AI navigation.
                </p>
            </div>

            <h2>Study Area</h2>
            <div style="display: grid; grid-template-columns: repeat(auto-fit, minmax(300px, 1fr)); gap: 20px; margin: 20px 0;">
                <div class="proposal-card">
                    <h3>Navigation Environment</h3>
                    <p>Assemble the Grand Central–Carnegie Hall corridor graph in EPSG:2263 using NYC DCM street centerlines; 
                    snap 161 intersections to the projected grid, overlay official hydrography and park polygons, and link each 
                    node to the nearest DOT camera through Voronoi zone IDs.</p>
                </div>
                <div class="proposal-card">
                    <h3>State Space</h3>
                    <p><strong>States S:</strong> Set of 161 intersection nodes (where streets cross) spanning a corridor bounded 
                    by extending ±2 streets and ±1 avenue from each endpoint: 40th to 59th St, Lexington to 8th Ave<br><br>
                    <strong>Initial State s₀:</strong> Grand Central (42nd & Park)<br>
                    <strong>Goal State s₉:</strong> Carnegie Hall (57th & 7th)</p>
                </div>
                <div class="proposal-card">
                    <h3>Camera Coverage</h3>
                    <p>Manhattan street network with 40 camera coverage zones in the corridor (Voronoi tessellation); dynamic 
                    traffic conditions; partially observable via camera sensors. Each camera provides multi-dimensional feature 
                    vectors encoding violations, density, infrastructure quality.</p>
                </div>
            </div>

            <h2>Methodology</h2>
            <div style="background: rgba(255, 255, 255, 0.95); padding: 25px; border-radius: 12px; margin: 20px 0; box-shadow: 0 2px 8px rgba(0,0,0,0.1);">
                <h3 style="color: #667eea; margin-top: 0;">Agent Framework</h3>
                <div style="display: grid; grid-template-columns: repeat(auto-fit, minmax(250px, 1fr)); gap: 15px; margin-bottom: 20px;">
                    <div>
                        <strong>Performance Measure:</strong> Minimize energetic cost (stress score) along navigation path
                    </div>
                    <div>
                        <strong>Environment:</strong> Manhattan street network with 40 camera zones, dynamic traffic conditions
                    </div>
                    <div>
                        <strong>Actuators:</strong> Directional movements (N, S, E, W) along street intersections
                    </div>
                    <div>
                        <strong>Sensors:</strong> Computer vision analysis of traffic camera imagery; multi-dimensional feature vectors
                    </div>
                </div>

                <h3 style="color: #667eea; margin-top: 20px;">Heuristic Design</h3>
                <div style="margin-top: 15px;">
                    <p style="margin-bottom: 10px;"><strong>Baseline: Manhattan Distance</strong></p>
                    <p style="background: #f8f9fa; padding: 15px; border-radius: 6px; margin-bottom: 15px;">
                        <code>h<sub>manhattan</sub>(n) = |x<sub>n</sub> - x<sub>goal</sub>| + |y<sub>n</sub> - y<sub>goal</sub>|</code><br>
                        <span style="color: #666; font-size: 0.9em;">Admissible but ignores environmental context.</span>
                    </p>

                    <p style="margin-bottom: 10px;"><strong>Learned Perceptual Heuristic</strong></p>
                    <p style="background: #f8f9fa; padding: 15px; border-radius: 6px; margin-bottom: 15px;">
                        <code>h<sub>learned</sub>(n) = w<sup>T</sup> f(n) + b</code><br>
                        <span style="color: #666; font-size: 0.9em;">
                        where <strong>f(n)</strong> represents the feature vector for node n, <strong>w</strong> denotes the learned 
                        weights from Ridge regression and <strong>b</strong> is the intercept term. Each intersection n inherits 
                        features from its nearest camera via Voronoi tessellation.
                        </span>
                    </p>

                    <p style="margin-bottom: 10px;"><strong>Adaptive Weighted A*</strong></p>
                    <p style="background: #f8f9fa; padding: 15px; border-radius: 6px;">
                        <code>f(n) = g(n) + W · h<sub>learned</sub>(n)</code><br>
                        <span style="color: #666; font-size: 0.9em;">
                        with W ∈ {1.0, 1.2, 1.5} to balance the exploration-exploitation tradeoff: higher weights prioritize 
                        heuristic guidance (faster search) while lower weights preserve optimality guarantees.
                        </span>
                    </p>
                </div>
            </div>

            <h2>Objectives</h2>
            <div style="display: grid; grid-template-columns: repeat(auto-fit, minmax(280px, 1fr)); gap: 20px; margin: 20px 0;">
                <div class="proposal-card">
                    <h3>Knowledge Base</h3>
                    <p>Engineer a data pipeline that captures a one-week window of traffic camera imagery, runs computer vision 
                    analysis, normalizes feature vectors and stores symbolic predicates such as <code>high_pedestrian</code> and 
                    <code>bike_violation</code> for search-time reasoning.</p>
                </div>
                <div class="proposal-card">
                    <h3>Perceptual Heuristic</h3>
                    <p>Fit a Ridge regression model on annotated camera data to learn energetic weights, calibrate cost scaling 
                    with stratified cross-validation and expose a reusable function returning h(n) = w<sup>T</sup> f<sub>zone(n)</sub> 
                    with interpretable coefficients.</p>
                </div>
                <div class="proposal-card">
                    <h3>A* Implementation</h3>
                    <p>Implement baseline A*, learned A* and adaptive weighted A* (W ∈ {1.0, 1.2, 1.5}); instrument node expansions, 
                    path costs and admissibility checks for the learned heuristic.</p>
                </div>
                <div class="proposal-card">
                    <h3>Evaluation</h3>
                    <p>Compare systems via Monte Carlo route sampling, Mean Absolute Error on stress predictions, search effort 
                    (nodes expanded, runtime), path diversity and permutation importance to surface dominant perceptual factors.</p>
                </div>
            </div>
        </div>
        
        <div class="refresh-indicator">
            <div class="spinner"></div>
            <span>Auto-refresh every 30s</span>
        </div>
    </div>
    
    <script>
        // Try API first (for local dev), fall back to static files
        const API_BASE = window.location.hostname === 'localhost' 
            ? 'http://localhost:8000' 
            : '';
        
        let cameraManifest = [];
        let useAPI = false;
        let map = null;
        let voronoiLayer = null;
        let cameraMarkers = {};
        let cameraStats = {};
        
        async function loadManifest() {
            try {
                // Try API first
                if (API_BASE) {
                    const response = await fetch(`${API_BASE}/api/manifest`);
                    const manifest = await response.json();
                    cameraManifest = manifest.cameras || [];
                    useAPI = true;
                    return;
                }
            } catch (error) {
                console.log('API not available, using static files');
            }
            
            // Fall back to static JSON file
            try {
                let response = await fetch('./manifest.json');
                if (!response.ok) {
                    response = await fetch('./docs/manifest.json');
                }
                if (!response.ok) {
                    response = await fetch('docs/manifest.json');
                }
                const manifest = await response.json();
                cameraManifest = manifest.cameras || [];
            } catch (error) {
                console.error('Failed to load manifest:', error);
                cameraManifest = [];
            }
        }
        
        async function fetchStats() {
            try {
                // Try API first (local dev)
                if (API_BASE && useAPI) {
                    const response = await fetch(`${API_BASE}/api/stats`);
                    const stats = await response.json();
                    updateDashboard(stats);
                    return;
                }
            } catch (error) {
                console.log('API not available, using static stats');
            }
            
            // Fall back to static JSON file
            try {
                let response = await fetch('./stats.json');
                if (!response.ok) {
                    response = await fetch('./docs/stats.json');
                }
                if (!response.ok) {
                    response = await fetch('docs/stats.json');
                }
                const stats = await response.json();
                updateDashboard(stats);
            } catch (error) {
                console.error('Failed to fetch stats:', error);
                updateDashboard({
                    totalImages: 0,
                    activeCameras: 0,
                    latestCapture: null,
                    cameraCounts: {},
                    storageInfo: 'No data collected yet',
                    latestImage: null
                });
            }
        }
        
        function updateDashboard(stats) {
            // Update stats cards
            document.getElementById('totalImages').textContent = (stats.totalImages || 0).toLocaleString();
            document.getElementById('activeCameras').textContent = stats.activeCameras || 0;
            
            if (stats.latestCapture) {
                const captureDate = new Date(stats.latestCapture);
                document.getElementById('latestCapture').textContent = captureDate.toLocaleTimeString();
            } else {
                document.getElementById('latestCapture').textContent = '--';
            }
            
            document.getElementById('storageInfo').textContent = stats.storageInfo || 'Loading...';
            
            // Store camera stats for map
            cameraStats = stats.cameraCounts || {};
            
            // Update image preview
            updateImagePreview(stats.latestImage);
            
            // Update map
            updateMap();
        }

        function updateImagePreview(latestImage) {
            const previewImage = document.getElementById('previewImage');
            const previewPlaceholder = document.getElementById('previewPlaceholder');
            const previewCameraName = document.getElementById('previewCameraName');
            const previewTimestamp = document.getElementById('previewTimestamp');
            const previewCapturedAt = document.getElementById('previewCapturedAt');
            
            if (!latestImage || !latestImage.image_path) {
                previewImage.style.display = 'none';
                previewPlaceholder.style.display = 'block';
                previewCameraName.textContent = '--';
                previewTimestamp.textContent = '--';
                previewCapturedAt.textContent = '--';
                return;
            }
            
            // Build image URL
            let imageUrl;
            if (API_BASE && useAPI) {
                imageUrl = `${API_BASE}/api/images/${latestImage.image_path}`;
            } else {
                imageUrl = null;
            }
            
            if (imageUrl) {
                previewImage.src = imageUrl;
                previewImage.style.display = 'block';
                previewPlaceholder.style.display = 'none';
            } else {
                previewImage.style.display = 'none';
                previewPlaceholder.textContent = 'Image preview unavailable (static mode)';
                previewPlaceholder.style.display = 'block';
            }
            
            previewCameraName.textContent = latestImage.camera_name || latestImage.camera_id || '--';
            previewTimestamp.textContent = latestImage.timestamp || '--';
            
            if (latestImage.captured_at) {
                const captureDate = new Date(latestImage.captured_at);
                previewCapturedAt.textContent = captureDate.toLocaleString();
            } else {
                previewCapturedAt.textContent = '--';
            }
        }

        function initializeMap() {
            // Initialize Leaflet map centered on Manhattan corridor
            map = L.map('cameraMap').setView([40.755, -73.977], 14);
            
            // Add OpenStreetMap tiles
            L.tileLayer('https://{s}.tile.openstreetmap.org/{z}/{x}/{y}.png', {
                attribution: '© OpenStreetMap contributors',
                maxZoom: 19
            }).addTo(map);
            
            // Create SVG overlay for Voronoi cells
            const svg = L.svg();
            svg.addTo(map);
            
            voronoiLayer = svg;
        }

        function computeVoronoiCells(cameras) {
            if (!cameras || cameras.length === 0) return null;
            
            // Check for d3-delaunay (may be exposed as d3 or Delaunay)
            const DelaunayClass = window.d3?.Delaunay || window.Delaunay;
            if (!DelaunayClass) {
                console.log('d3-delaunay not available');
                return null;
            }
            
            try {
                // Convert lat/lon to map coordinates
                const size = map.getSize();
                const points = cameras.map(cam => {
                    const point = map.latLngToContainerPoint([cam.latitude, cam.longitude]);
                    return [point.x, point.y];
                });
                
                // Compute Voronoi diagram using d3-delaunay
                const delaunay = DelaunayClass.from(points);
                const voronoi = delaunay.voronoi([0, 0, size.x, size.y]);
                
                return { voronoi, points, cameras };
            } catch (e) {
                console.warn('Voronoi computation failed:', e);
                return null;
            }
        }

        function drawVoronoiCells(voronoiData) {
            if (!voronoiData || !voronoiLayer) return;
            
            const svg = voronoiLayer._container;
            if (!svg) return;
            
            // Clear existing cells
            const existing = svg.querySelectorAll('.voronoi-cell');
            existing.forEach(el => el.remove());
            
            const svgGroup = document.createElementNS('http://www.w3.org/2000/svg', 'g');
            svgGroup.setAttribute('class', 'voronoi-overlay');
            svg.appendChild(svgGroup);
            
            // Draw Voronoi cells
            voronoiData.cameras.forEach((camera, i) => {
                try {
                    const cell = voronoiData.voronoi.renderCell(i);
                    if (cell) {
                        const path = document.createElementNS('http://www.w3.org/2000/svg', 'path');
                        path.setAttribute('class', 'voronoi-cell');
                        path.setAttribute('d', cell);
                        path.setAttribute('data-camera-id', camera.id);
                        const fillColor = camera.priority === 'high' ? 'rgba(245, 101, 101, 0.15)' : 'rgba(102, 126, 234, 0.1)';
                        const strokeColor = camera.priority === 'high' ? 'rgba(245, 101, 101, 0.4)' : 'rgba(102, 126, 234, 0.3)';
                        path.style.fill = fillColor;
                        path.style.stroke = strokeColor;
                        path.style.strokeWidth = '1';
                        path.style.pointerEvents = 'none';
                        
                        path.addEventListener('mouseover', function() {
                            this.style.fillOpacity = '0.3';
                            const stats = cameraStats[camera.id] || { count: 0, lastCapture: null };
                            showCameraPopup(camera, stats);
                        });
                        
                        path.addEventListener('mouseout', function() {
                            this.style.fillOpacity = '1';
                        });
                        
                        svgGroup.appendChild(path);
                    }
                } catch (e) {
                    console.warn(`Failed to render cell for camera ${i}:`, e);
                }
            });
        }

        function updateMap() {
            if (!map || !cameraManifest || cameraManifest.length === 0) return;
            
            // Clear existing markers
            Object.values(cameraMarkers).forEach(marker => marker.remove());
            cameraMarkers = {};
            
            // Add camera markers
            cameraManifest.forEach(camera => {
                const stats = cameraStats[camera.id] || { count: 0, lastCapture: null };
                
                // Create custom icon based on priority and count
                const iconColor = camera.priority === 'high' ? '#f56565' : '#667eea';
                const iconSize = stats.count > 0 ? 20 : 12;
                
                const customIcon = L.divIcon({
                    className: 'camera-marker',
                    html: `<div style="width: ${iconSize}px; height: ${iconSize}px; background: ${iconColor}; border: 2px solid white; border-radius: 50%; box-shadow: 0 2px 4px rgba(0,0,0,0.3);"></div>`,
                    iconSize: [iconSize, iconSize],
                    iconAnchor: [iconSize/2, iconSize/2]
                });
                
                const marker = L.marker([camera.latitude, camera.longitude], { icon: customIcon })
                    .addTo(map)
                    .on('mouseover', function() {
                        showCameraPopup(camera, stats);
                    })
                    .on('click', function() {
                        showCameraPopup(camera, stats, true);
                    });
                
                cameraMarkers[camera.id] = marker;
            });
            
            // Update Voronoi cells on map move/zoom
            function updateVoronoi() {
                const voronoiData = computeVoronoiCells(cameraManifest);
                if (voronoiData) {
                    drawVoronoiCells(voronoiData);
                }
            }
            
            // Initial Voronoi render (with delay to ensure library loaded)
            setTimeout(updateVoronoi, 500);
            
            map.off('moveend', updateVoronoi);
            map.off('zoomend', updateVoronoi);
            map.on('moveend', updateVoronoi);
            map.on('zoomend', updateVoronoi);
        }

        function showCameraPopup(camera, stats, persistent = false) {
            const data = stats || cameraStats[camera.id] || { count: 0, lastCapture: null };
            const lastCapture = data.lastCapture 
                ? new Date(data.lastCapture).toLocaleString()
                : 'No captures yet';
            
            const popupContent = `
                <div class="camera-popup">
                    <div class="camera-popup-header">
                        <div class="camera-popup-name">${camera.name}</div>
                        <div class="camera-popup-badge ${camera.priority}">${camera.priority}</div>
                    </div>
                    <div class="camera-popup-meta">${camera.area}</div>
                    <div class="camera-popup-count">${data.count.toLocaleString()}</div>
                    <div class="camera-popup-last">Last: ${lastCapture}</div>
                </div>
            `;
            
            if (cameraMarkers[camera.id]) {
                cameraMarkers[camera.id].bindPopup(popupContent, {
                    className: 'camera-popup-container',
                    closeOnClick: !persistent
                });
                if (persistent) {
                    cameraMarkers[camera.id].openPopup();
                }
            }
        }
        
        function showError(message) {
            const errorDiv = document.getElementById('errorMessage');
            errorDiv.textContent = message;
            errorDiv.style.display = 'block';
            setTimeout(() => {
                errorDiv.style.display = 'none';
            }, 5000);
        }
        
        // Initial load
        async function initialize() {
            await loadManifest();
            initializeMap();
            await fetchStats();
        }
        
        initialize();
        
        // Auto-refresh every 30 seconds
        setInterval(fetchStats, 30000);
    </script>
</body>
</html>
